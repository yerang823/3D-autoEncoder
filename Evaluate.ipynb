{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose, BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, EarlyStopping\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from data import *\n",
    "\n",
    "\n",
    "from metrics import iou_score\n",
    "from metrics import jaccard_score\n",
    "from metrics import f_score\n",
    "from metrics import f2_score\n",
    "from metrics import dice_score\n",
    "\n",
    "\n",
    "from losses import jaccard_loss\n",
    "from losses import bce_jaccard_loss\n",
    "from losses import cce_jaccard_loss\n",
    "from losses import dice_loss\n",
    "from losses import bce_dice_loss\n",
    "from losses import cce_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 4\n",
    "alpha = 0.25\n",
    "beta = 0.75\n",
    "\n",
    "  \n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def balanced_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    BL = alpha * CE\n",
    "    \n",
    "    return K.sum(BL, axis=1)\n",
    "\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = alpha * K.pow(1-pt, gamma) * CE\n",
    "    \n",
    "    return K.sum(FL, axis=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def cus_loss(y_true, y_pred):\n",
    "    \n",
    "    return (1 - beta) * focal_loss(y_true, y_pred) + beta * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'cus_loss': cus_loss,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'f1score' : f1score,\n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'balanced_loss' : balanced_loss,\n",
    "    'focal_loss' : focal_loss,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "    'cus_loss' : cus_loss,\n",
    "        \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading data done\n",
      "(196, 512, 512, 1)\n",
      "(196, 512, 512, 1)\n",
      "(48, 512, 512, 1)\n",
      "(48, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "img_size = 512\n",
    "\n",
    "print(\"loading data\")\n",
    "\n",
    "train_image = np.load('../data/npy/train_'+str(img_size)+'.npy')\n",
    "train_label = np.load('../data/npy/label_'+str(img_size)+'.npy')\n",
    "test_image =np.load('../data/npy/test_'+str(img_size)+'.npy')\n",
    "test_label = np.load('../data/npy/test_label_'+str(img_size)+'.npy')\n",
    "\n",
    "train_image = train_image/255\n",
    "\n",
    "train_label = train_label/255\n",
    "\n",
    "test_image = test_image/255\n",
    "\n",
    "test_label = test_label/255\n",
    "\n",
    "print(\"loading data done\")\n",
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "print(test_image.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/jin36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../result/model_save/model_spine_lr_0_0001_padding_image_best_512.h5', custom_objects = {'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef,'recall': recall,'precision': precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_Thresh(preds_test,Thresh_value):\n",
    "    \n",
    "    preds_mask = np.ndarray((len(test_label),img_size, img_size, 1), dtype=np.float32)\n",
    "  \n",
    "    preds_mask0 = preds_test[:,:,:,0] > Thresh_value\n",
    "  \n",
    "    preds_mask[:,:,:,0] = preds_mask0*1\n",
    "    \n",
    "    return preds_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = model.predict(image_test, batch_size= 8, verbose=1)\n",
    "\n",
    "preds_mask = preds_Thresh(predic,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한장 한장 결과를 뽑아서 평균내서 결과를 보는 것\n",
    "\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "precision_list = []\n",
    "acc_list = []\n",
    "dice_list = []\n",
    "\n",
    "for i in range(len(test_label)):\n",
    "    \n",
    "    seg1 = preds_mask[i,:,:,0].flatten()\n",
    "    gt1 = test_label[i,:,:,0].flatten()\n",
    "\n",
    "    seg1_n = seg1 == 0\n",
    "    seg1_t = seg1 == 1\n",
    "\n",
    "    gt1_n = gt1 == 0\n",
    "    gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "    tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "    fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "    tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "    fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "#     print('Sensitivity : ', sensitivity)\n",
    "\n",
    "    specificity = tn / (tn+fp)\n",
    "#     print('Specificity : ', specificity)\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "#     print('Precision : ', precision)\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "#     print('Accuracy : ', acc)\n",
    "\n",
    "    dice = (2*tp) / (2*tp + fp + fn)\n",
    "#     print('DSC : ', dice)\n",
    "    \n",
    "    \n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    precision_list.append(precision)\n",
    "    acc_list.append(acc)\n",
    "    dice_list.append(dice)\n",
    "    \n",
    "\n",
    "sensitivity_avg = np.mean(sensitivity_list)\n",
    "specificity_avg = np.mean(specificity_list)\n",
    "precision_avg = np.mean(precision_list)\n",
    "acc_avg = np.mean(acc_list)\n",
    "dice_avg = np.mean(dice_list)\n",
    "\n",
    "\n",
    "sensitivity_max = np.max(sensitivity_list)\n",
    "specificity_max = np.max(specificity_list)\n",
    "precision_max = np.max(precision_list)\n",
    "acc_max = np.max(acc_list)\n",
    "dice_max = np.max(dice_list)\n",
    "\n",
    "sensitivity_std = np.std(sensitivity_list)\n",
    "specificity_std = np.std(specificity_list)\n",
    "precision_std = np.std(precision_list)\n",
    "acc_std = np.std(acc_list)\n",
    "dice_std = np.std(dice_list)\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print('sensitivity_avg : ', sensitivity_avg)\n",
    "print('specificity_avg : ', specificity_avg)\n",
    "print('precision_avg : ', precision_avg)\n",
    "print('acc_avg : ', acc_avg)\n",
    "print('dice_avg : ', dice_avg)\n",
    "print('-'*30)\n",
    "\n",
    "print('sensitivity_std : ', sensitivity_std)\n",
    "print('specificity_std : ', specificity_std)\n",
    "print('precision_std : ', precision_std)\n",
    "print('acc_max : ', acc_max)\n",
    "print('dice_max : ', dice_max)\n",
    "print('-'*30)\n",
    "\n",
    "print('sensitivity_max : ', sensitivity_max)\n",
    "print('specificity_max : ', specificity_max)\n",
    "print('precision_max : ', precision_max)\n",
    "print('acc_max : ', acc_max)\n",
    "print('dice_max : ', dice_max)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터의 결과를 보는 것\n",
    "\n",
    "seg1 = preds_mask[:,:,:,0].flatten()\n",
    "gt1 = test_label[:,:,:,0].flatten()\n",
    "\n",
    "seg1_n = seg1 == 0\n",
    "seg1_t = seg1 == 1\n",
    "\n",
    "gt1_n = gt1 == 0\n",
    "gt1_t = gt1 == 1\n",
    "\n",
    "\n",
    "tp = np.sum(seg1_t&gt1_t)\n",
    "\n",
    "fp = np.sum(seg1_t&gt1_n)\n",
    "\n",
    "tn = np.sum(seg1_n&gt1_n)\n",
    "\n",
    "fn = np.sum(gt1_t&seg1_n)\n",
    "\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity : ', sensitivity)\n",
    "\n",
    "\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity : ', specificity)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "print('Precision : ', precision)\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy : ', acc)\n",
    "\n",
    "dice = (2*tp) / (2*tp + fp + fn)\n",
    "print('DSC : ', dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_label_ravel = np.ravel(test_label)\n",
    "image_test_label_ravel_cur = image_test_label_ravel.astype(np.bool)\n",
    "\n",
    "\n",
    "predic_ravel_1 = np.ravel(model.predict(test_image, batch_size=104,verbose=1))\n",
    "predic_ravel_1 = predic_ravel_1.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_1, recall_1, thresholds_1 = precision_recall_curve(image_test_label_ravel_cur, predic_ravel_1)\n",
    "\n",
    "average_precision_score_1 = average_precision_score(image_test_label_ravel_cur, predic_ravel_1)\n",
    "\n",
    "fpr1 , tpr1 , thresholds1 = roc_curve(image_test_label_ravel_cur, predic_ravel_1)\n",
    "\n",
    "roc_auc_score_1 = roc_auc_score(image_test_label_ravel_cur,predic_ravel_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))        \n",
    "plt.title('Precision Recall Curve',fontsize=20)\n",
    "plt.xlabel('Recall',fontsize=20)\n",
    "plt.ylabel('Precision',fontsize=20)\n",
    "\n",
    "\n",
    "plt.plot(recall_1, precision_1, label='AP = %0.3f'%average_precision_score_1)\n",
    "\n",
    "\n",
    "\n",
    "# plt.ylim(0.5,1)\n",
    "# plt.xlim(0.5,1)\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.show()\n",
    "# fig.savefig('../result/curve_figure/Final Precision_Recall_curve.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))        \n",
    "plt.title('Receiver Operating Characteristic',fontsize=20)\n",
    "plt.xlabel('True Positive Rate',fontsize=20)\n",
    "plt.ylabel('False Positive Rate',fontsize=20)\n",
    "\n",
    "\n",
    "plt.plot(fpr1 , tpr1, label='AUC = %0.3f'%roc_auc_score_1)\n",
    "\n",
    "# plt.ylim(0.8,1)\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.show()\n",
    "# fig.savefig('../result/curve_figure/Final Receiver Operating Characteristic.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
